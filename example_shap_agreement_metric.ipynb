{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# ShapAgreement Metric\n",
    "The notebook demonstrates how to compute the ShapAgreement between models. For demonstration purpose we provided the shap values for all models trained on set `12-all`."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b402f89bedf6b02"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6cd098a48ea53ea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_object(fname):\n",
    "    try:\n",
    "        with open(fname + \".pickle\", \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as ex:\n",
    "        print(\"Error during unpickling object (Possibly unsupported):\", ex)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4b7c7a88a75a509",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Selecting Models To Compare\n",
    "In the list `MODEL_LIST` we can specify the models folder names to include in the ShapAgreement computation. We than load the training data to get the feature names as well as the training samples."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f7d1bedf63372b4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "MODEL_LIST = [\n",
    "    'MLP', 'KernelRidge', 'KNN', 'BaggedKNN', 'LassoRegression', 'EleasticNet', \n",
    "    'SVRegression', 'RandomForest', 'CatBoost', 'XGBoost'\n",
    "]\n",
    "\n",
    "# Load shared dataset\n",
    "data = load_object('data/example_training_set/training_set')\n",
    "x, groups, y, x_names = data['x'], data['group'], data['y'], data['x_names']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "260fd7ec2de1a6e1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Aggregation Function\n",
    "Next we define our feature grouping function that takes in all feature names  constructed as:\n",
    "\n",
    "`resting state` _ `frequency band` _ `extraction method` _ `channel name`\n",
    "\n",
    "`resting state`: eyes open (EO), eyes closed (EC)\n",
    "`frequency band`: the frequency band the feature was extracted from (delta, theta, alpha, beta, whole_spectrum)\n",
    "`extraction method`: the name of the extraction method used to compute the feature\n",
    "`channel name`: the name/label of the channel\n",
    "\n",
    "and outputs a list of feature groups. For this demonstration we provided the function to group features based on the frequency band they were extracted from. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "776ec2704c875028"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "freq_bands = ['delta', 'theta', 'alpha', 'beta', 'whole_spec']\n",
    "\n",
    "def group_freq_bands_shap(label_arr):\n",
    "    feature_groups_fb = []\n",
    "    n_labels_fb = []\n",
    "    \n",
    "    for fb in freq_bands:\n",
    "        feature_group_idx = [i for i, name in enumerate(label_arr) if fb in name and\n",
    "                             (fb != 'whole_spec' or not any(ofb in name for ofb in freq_bands[:-1]))]\n",
    "\n",
    "        if feature_group_idx:\n",
    "            feature_groups_fb.append(feature_group_idx)\n",
    "            n_labels_fb.append(fb)\n",
    "\n",
    "    return n_labels_fb, feature_groups_fb"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67c9cdd8db668e41",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper Functions\n",
    "Following functions help to process the shap values of the models, group the features, compute the aggregated shap values for the feature groups in order to create group ranks and cluster the rank order correlation scores between all models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4cdfca2f3f8c4a3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_model(model, x, x_names):\n",
    "    shap_dict = load_object(f'models/{model}/shap_values')\n",
    "    fold = shap_dict['fold']\n",
    "    shap_values = shap_dict['shap_values']\n",
    "\n",
    "    # Select data based on fold\n",
    "    x_test = [x[i] for i in fold[1]]\n",
    "    x_test_df = pd.DataFrame(x_test, columns=x_names)\n",
    "\n",
    "    # Aggregate SHAP values by feature groups\n",
    "    n_labels, feature_groups = group_freq_bands_shap(x_names)\n",
    "    grouped_shap_values = np.zeros((len(x_test), len(n_labels)))\n",
    "    for i, group in enumerate(feature_groups):\n",
    "        grouped_shap_values[:, i] = np.sum(shap_values[:, group], axis=1)\n",
    "\n",
    "    # Compute mean absolute SHAP values and sort features\n",
    "    mean_abs_shap = np.abs(grouped_shap_values).mean(axis=0)\n",
    "    sorted_features = sorted(zip(mean_abs_shap, n_labels), reverse=True)\n",
    "    return model, [label for _, label in sorted_features], [val for val in sorted_features]\n",
    "\n",
    "def compute_correlation(ranks):\n",
    "    return np.array([[spearmanr(x, l).correlation for l in ranks] for x in ranks])\n",
    "\n",
    "def hierarchical_clustering(correlation_matrix):\n",
    "    distance_matrix = np.sqrt(2 * (1 - correlation_matrix))\n",
    "    linkage = hierarchy.linkage(distance_matrix, method='complete')\n",
    "    dendrogram = hierarchy.dendrogram(linkage, no_plot=True)\n",
    "    return dendrogram['leaves']\n",
    "\n",
    "def plot_sorted_correlation_matrix(sorted_corr_matrix, labels):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(sorted_corr_matrix, annot=True, cmap='coolwarm', xticklabels=labels, yticklabels=labels, annot_kws={\"fontsize\": 8})\n",
    "    plt.title(f'Ranked Ordered Correlation (FeaturesGroupedByFrequencyBand) fold {fold_n}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7727e04de492a41f",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Computing The ShapAgreement\n",
    "Next we compute the ShapAgreement among our models and plot the result in a clustered matrix."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d0aa78987cfc12c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = [process_model(model, x, x_names) for model in MODEL_LIST]\n",
    "feature_ranks = [result[1] for result in results]\n",
    "\n",
    "# Encode feature ranks\n",
    "le = LabelEncoder()\n",
    "encoded_ranks = [le.fit_transform(rank) for rank in feature_ranks]\n",
    "\n",
    "# Compute correlation matrix and perform hierarchical clustering\n",
    "corr_matrix = compute_correlation(encoded_ranks)\n",
    "ordered_indices = hierarchical_clustering(corr_matrix)\n",
    "sorted_corr_matrix = corr_matrix[ordered_indices][:, ordered_indices]\n",
    "sorted_labels = np.array([result[0] for result in results])[ordered_indices]\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plot_sorted_correlation_matrix(sorted_corr_matrix, sorted_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
